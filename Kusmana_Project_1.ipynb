{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ1om7qVGg2R0OK5S+dvYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckusmana21/DS2002-Data-Project-1/blob/main/Kusmana_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 1: REFLECTION"
      ],
      "metadata": {
        "id": "rYIbag3KnPgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Reflecting on this project, the part that I struggled with the most was, surprisingly, not building the code itself (in fact, this part was more streamlined thanks to internet resources and past class notes) -- but rather, understanding what the benchmarks are asking for. I think it requires that I understand the terms used. For instance, what does it mean to \"ingest\" a file? Does the script need to treat JSON and CSV files differently? How does one put \"the option to convert any source to any target\" - and what does that mean, in fact? I spent quite some time researching these questions and coming up with a simpler \"checklist\" for what the script needs to produce, as well as the correct deliverable and outputs. I found that having this \"checklist\" considerably helped me when I figured out how to get started with the code, and when I checked for whether the script was doing what I wanted it to do.\n",
        "* I thought that conveting the differentfile formats (CSV to JSON and JSON to CSV) was easier than I thought, because pandas has simple methods (to_csv() and to_json(), both of which I used in part 2. A challenge that stood out to me, however, was writing codes that would allow users to specifcy the format that they wanted for this part. I researched stackoverflow (as indicated in the comments) to include all possible pathways for the data conversion. Nevertheless, another feature python had that greatly helped me is json_normalize() and pd.read_csv(). Once I found out how to assemble the codes together, the initial processing/ingesting, as well as the modifying steps, become simpler.\n",
        "*In the future, I thought this utility would help me to integrate multiple data sources, especially when it comes to converting data from one format to another. An example that came to mind is converting CSV from a data dump to SQL for some cleanup, or to JSON for a publicy available API url upload. I did not do this for the project, but it would be interesting to see how similar codes would work when used to scrape websites and combining different dataset formats. It would help the data modification/transformation, too. This code, especially Part 3, would allow for quick conversion, in addition to letting us add and drop columns, all in the same pieline -- meaning, we don't have to write longer and more complicated scripts for just one output (that is , the modified file).\n",
        "* Finally, another thing I appreciated about this project is that it worked with both smaller files (such as the one I am using to test the codes) and larger ones. Waiting time may differ, but the project seems scalable and versatile.\n",
        "\n"
      ],
      "metadata": {
        "id": "kIYtbGDanU7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2: CODE"
      ],
      "metadata": {
        "id": "-bgX5ijJnTCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the first step of the process, which is creating the \"skeleton\" of the code. The second step is for processing the actual CSV and JSON files. For disclosure, I have indicated where I used internet resources or ChatGPT in the comment when appropriate, such as when fixing errors."
      ],
      "metadata": {
        "id": "XW8p_lSmi65V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import sqlite3\n",
        "import requests\n",
        "\n",
        "# PART 1a: This is for ingesting/processing the CSV file.\n",
        "def ingest_csv(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        print(f\"Data ingested from CSV: {len(data)} records and {len(data.columns)} columns\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error ingesting CSV file: {e}\")\n",
        "        # NOTE: I consulted ChatGPT to create the line above. The prompt was, \"how do I how do I write an error message if the CSV file doesn't exist or if I cannot open it?\"\n",
        "        return\n",
        "\n",
        "# PART 1b: This is for ingesting/processing the JSON file.\n",
        "def ingest_json(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        df = pd.json_normalize(data)\n",
        "        print(f\"Data ingested from JSON: {len(df)} records and {len(df.columns)} columns\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching or parsing JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "# PART 2A: This is for converting the data.\n",
        "# NOTE: I consulted \"https://stackoverflow.com/questions/43876246/read-and-process-a-text-file-and-save-to-csv\" to find out how to correctly save the files, where I found out about \"convert_to_csv\".\n",
        "def convert_to_csv(df, output_path):\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Data saved as CSV at {output_path}\")\n",
        "\n",
        "def convert_to_json(df, output_path):\n",
        "    df.to_json(output_path, orient='records')\n",
        "    print(f\"Data saved as JSON at {output_path}\")\n",
        "\n",
        "# PART 2B: This is for converting the data, BUT based on user's choice.\n",
        "def convert_data(data, output_format, output_path, db_path=None, table_name=None):\n",
        "    if output_format == 'csv':\n",
        "        # Convert to CSV\n",
        "        convert_to_csv(data, output_path)\n",
        "    elif output_format == 'json':\n",
        "        # Convert to JSON\n",
        "        convert_to_json(data, output_path)\n",
        "    elif output_format == 'sql':\n",
        "        if db_path and table_name:\n",
        "            # Convert to SQL database\n",
        "            save_to_sql(data, db_path, table_name)\n",
        "        else:\n",
        "            print(\"Please provide both db_path and table_name for SQL conversion.\")\n",
        "    else:\n",
        "        print(\"Unsupported output format. Please choose 'csv', 'json', or 'sql'.\")\n",
        "\n",
        "\n",
        "# PART 3: This is for modyfing the columns - such as, adding or dropping columns.\n",
        "def modify_columns(df, columns_to_drop=None, new_columns=None):\n",
        "    if columns_to_drop:\n",
        "        df = df.drop(columns=columns_to_drop)\n",
        "    if new_columns:\n",
        "        for col, value in new_columns.items():\n",
        "            df[col] = value\n",
        "    print(f\"Modified data: {len(df)} records and {len(df.columns)} columns\")\n",
        "    return df\n",
        "\n",
        "# PART 4: This is for savaing the data files (CSV or JSON) locally.\n",
        "def save_to_local(df, output_path, file_format):\n",
        "    if file_format == 'csv':\n",
        "        convert_to_csv(df, output_path)\n",
        "    elif file_format == 'json':\n",
        "        convert_to_json(df, output_path)\n",
        "    else:\n",
        "        print(\"Unsupported file format. Make sure to use CSV or JSON\")\n",
        "\n",
        "# PART 5 comes in the next part. It is also combined in PART 1a and PART 1b."
      ],
      "metadata": {
        "id": "6VJ75oPqcFbn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is for testing the codes using two datasets: one a CSV (from another class) containing information of car sales in the U.S, and another a JSON file (its API url is publicly available) containing information of colleges/universities in the U.S.\n",
        "\n",
        "\n",
        "*   I have chosen to save the files locally. However, I included a potential way to save it on a SQL database at the end as a comment.\n",
        "*   I tested the modified files at the end (head of each)\n",
        "\n"
      ],
      "metadata": {
        "id": "6BuYYDZdhIg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 5 (summary)\n",
        "if __name__ == \"__main__\":\n",
        "    csv_data = ingest_csv('/content/USA_cars_datasets.csv')\n",
        "    json_data = ingest_json('http://universities.hipolabs.com/search?country=United+States')\n",
        "\n",
        "    # This is for modifying the data. I am dropping the column \"country\" and adding \"price\" for the CSV, and adding the column \"Global Rnaking\" in the JSON\n",
        "    # You can customize which columns to drop or add\n",
        "    csv_data2 = modify_columns(csv_data, columns_to_drop=['country'], new_columns={'price': 'placeholder value'}) # here, the placeholder values are the prices of the cars.\n",
        "    json_data2 = modify_columns(json_data, new_columns={'Global Ranking': 'another placeholder value'}) # here, the placeholder values are the ranking of the schools.\n",
        "\n",
        "    # This is for saveing the newly modified files locally. Frist for the CSV, and second for the JSON.\n",
        "    save_to_local(csv_data2, 'processed_cars_data.csv', 'csv')\n",
        "    save_to_local(json_data2, 'processed_universities_data.json', 'json')\n",
        "\n",
        "    # This is for saving the data to SQL instead of locally. However, I wasn't able to run this correctly, so I'm including this as a comment:\n",
        "    ## save_to_sql(json_data2, 'data.db', 'json_table')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8VxGjcJcbMS",
        "outputId": "f7020eba-cfdb-4124-fa51-fcaa140eb422"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ingested from CSV: 2499 records and 13 columns\n",
            "Data ingested from JSON: 2335 records and 6 columns\n",
            "Modified data: 2499 records and 12 columns\n",
            "Modified data: 2335 records and 7 columns\n",
            "Data saved as CSV at processed_cars_data.csv\n",
            "Data saved as JSON at processed_universities_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just to view the first few rows of both files to see if they have been modified correctly, confriming that the the values in \"Data ingested from __\" and \"Modified data\" are correct."
      ],
      "metadata": {
        "id": "d_WK2UYQh-ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(csv_data2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nm6_bjshubn",
        "outputId": "9fa2571f-077d-4053-98e0-e7214825188b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0              price      brand    model  year   title_status  \\\n",
            "0           0  placeholder value     toyota  cruiser  2008  clean vehicle   \n",
            "1           1  placeholder value       ford       se  2011  clean vehicle   \n",
            "2           2  placeholder value      dodge      mpv  2018  clean vehicle   \n",
            "3           3  placeholder value       ford     door  2014  clean vehicle   \n",
            "4           4  placeholder value  chevrolet     1500  2018  clean vehicle   \n",
            "\n",
            "   mileage   color                  vin        lot       state      condition  \n",
            "0   274117   black    jtezu11f88k007763  159348797  new jersey   10 days left  \n",
            "1   190552  silver    2fmdk3gc4bbb02217  166951262   tennessee    6 days left  \n",
            "2    39590  silver    3c4pdcgg5jt346413  167655728     georgia    2 days left  \n",
            "3    64146    blue    1ftfw1et4efc23745  167753855    virginia  22 hours left  \n",
            "4     6654     red    3gcpcrec2jg473991  167763266     florida  22 hours left  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_data2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGUHt1mpiIRx",
        "outputId": "629a815d-32e6-40f5-c7b1-c77611bac376"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    name alpha_two_code  \\\n",
            "0                    Marywood University             US   \n",
            "1                  Lindenwood University             US   \n",
            "2                    Sullivan University             US   \n",
            "3  Florida State College at Jacksonville             US   \n",
            "4                      Xavier University             US   \n",
            "\n",
            "                      web_pages state-province           domains  \\\n",
            "0     [http://www.marywood.edu]           None    [marywood.edu]   \n",
            "1  [http://www.lindenwood.edu/]           None  [lindenwood.edu]   \n",
            "2       [https://sullivan.edu/]           None    [sullivan.edu]   \n",
            "3       [https://www.fscj.edu/]           None        [fscj.edu]   \n",
            "4     [https://www.xavier.edu/]           None      [xavier.edu]   \n",
            "\n",
            "         country             Global Ranking  \n",
            "0  United States  another placeholder value  \n",
            "1  United States  another placeholder value  \n",
            "2  United States  another placeholder value  \n",
            "3  United States  another placeholder value  \n",
            "4  United States  another placeholder value  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2b: This is specifically for converting the files to the desired output.\n"
      ],
      "metadata": {
        "id": "yr6VfwAYm-Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 2b: This is specifically for converting the files to the desired output.\n",
        "if __name__ == \"__main__\":\n",
        "    # This will allow user to select input. NOTE: I found out how to use the \"input\" function from \"https://stackoverflow.com/questions/3345202/getting-user-input\".\n",
        "    input_type = input(\"Enter the input type (csv or json): \").lower()\n",
        "    output_type = input(\"Enter the chosen output type (csv or json or sql): \").lower()\n",
        "\n",
        "    # This is for processing/ingesting the data\n",
        "    if input_type == 'csv':\n",
        "        data = ingest_csv('/content/USA_cars_datasets.csv')\n",
        "    elif input_type == 'json':\n",
        "        data = ingest_json('http://universities.hipolabs.com/search?country=United+States')\n",
        "    else:\n",
        "        print(\"Unsupported input type. Please choose 'csv' or 'json'.\")\n",
        "        data = None\n",
        "\n",
        "    # This is for converting data type, based on user's chocies.\n",
        "    if data is not None:\n",
        "        if output_type == 'csv':\n",
        "            convert_data(data, 'csv', 'output.csv')\n",
        "        elif output_type == 'json':\n",
        "            convert_data(data, 'json', 'output.json')\n",
        "        elif output_type == 'sql':\n",
        "            # NOTE: for the SQL converstion, user have to put in the database path and name of the table\n",
        "            db_path = input(\"Enter the path for the database (e.g., 'data.db'): \")\n",
        "            table_name = input(\"Enter the table name for the SQL database: \")\n",
        "            convert_data(data, 'sql', output_path=None, db_path=db_path, table_name=table_name)\n",
        "        else:\n",
        "            print(\"Unsupported output type. Please choose 'csv', 'json', or 'sql'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aHJMhnglM1G",
        "outputId": "c8c84cf0-e528-40b5-9f49-f8d2621ee420"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the input type (csv or json): CSV\n",
            "Enter the chosen output type (csv or json or sql): JSON\n",
            "Data ingested from CSV: 2499 records and 13 columns\n",
            "Data saved as JSON at output.json\n"
          ]
        }
      ]
    }
  ]
}